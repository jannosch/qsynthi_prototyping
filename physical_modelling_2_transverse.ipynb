{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Physical Modelling 2\n",
    "- Transverse Wave\n",
    "- Can reduce spatial resolution\n",
    "- "
   ],
   "id": "7956af42643b0c8a"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.patches as patches\n",
    "from IPython.display import Audio\n",
    "from scipy.io.wavfile import write\n",
    "from datetime import datetime\n",
    "import subprocess"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def get_interpolated(array, index):\n",
    "    if not hasattr(index, \"__len__\") or len(index) < 1: return array # if scalar\n",
    "    return (1 - (index[0] % 1)) * get_interpolated(array[int(np.floor(index[0]))], index[1:]) + (index[0] % 1) * get_interpolated(array[int(np.ceil(index[0]))], index[1:])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43a188074d7eaff3",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "get_interpolated(np.array([[1, 2],[3, 4]]), [0.5])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "954deb97c398862c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Simulation",
   "id": "8829280fd1e1e5f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import simulation\n",
    "\n",
    "n = 128\n",
    "sim_speed = 0.004\n",
    "sim_fps = 400\n",
    "duration = 6\n",
    "frame_amount = duration * sim_fps\n",
    "\n",
    "initial_state = np.array([[simulation.gaussian(x, y, n, offset=[-0.6, 0.0], width=0.15) for x in range(n)] for y in range(n)])\n",
    "potential = np.array([[simulation.parabola(x, y, n, offset=[0, 0], factor=10000) for x in range(n)] for y in range(n)])\n",
    "\n",
    "multi_slit = [(-15, -13), (-8, -6), (-1, 1), (6, 8), (13, 15)]\n",
    "double_slit = [(-4, -2), (2, 4)]\n",
    "single_slit = [(-2, 2)]\n",
    "slits = double_slit\n",
    "\n",
    "frames = simulation.sim(n, sim_fps, duration, slits, sim_speed, initial_state=initial_state, potential=potential)"
   ],
   "id": "980b36c1898fe202"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Video",
   "id": "c6cae44c239c53b0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 39,
   "source": [
    "# create visual barrier for plot\n",
    "def visual_barrier(barrier_gaps):\n",
    "    start = 0\n",
    "    rects = []\n",
    "    for g in barrier_gaps:\n",
    "        end = n//2 + g[0]\n",
    "        rect = patches.Rectangle((n//2 - 1.5, start - 0.5), 1, end - start, linewidth=0, facecolor='#60b0ff')\n",
    "        start = n//2 + g[1]\n",
    "        rects.append(rect)\n",
    "    rects.append(patches.Rectangle((n//2 - 1.5, start - 0.5), 1, n - start, linewidth=0, facecolor='#60b0ff'))\n",
    "    return rects"
   ],
   "id": "22156a0dfcf6bcd4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# FuncAnimation\n",
    "video_fps = 20\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.axis('off')  # big performance boost\n",
    "\n",
    "data = pow(np.abs(frames[0]), 2.0/3.0)\n",
    "cax = ax.imshow(data, cmap='inferno', vmin=0, vmax=1)\n",
    "for b in visual_barrier(slits):\n",
    "    ax.add_patch(b)\n",
    "fig.colorbar(cax)  # no performance impact (?)\n",
    "\n",
    "def animate(i):\n",
    "    cax.set_array(pow(np.abs(frames[i * sim_fps // video_fps]), 2.0/3.0))\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, frames=frame_amount * video_fps // sim_fps)\n",
    "video_filename = f'output/simulation_{datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")}.mp4'\n",
    "\n",
    "anim.save(video_filename, fps=video_fps, dpi=150, bitrate=4000)\n",
    "\n",
    "print(f'video saved as {video_filename}')"
   ],
   "id": "6c1f72bd3c44dad0",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sonification"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "80163b117f61d1c4"
  },
  {
   "cell_type": "code",
   "source": [
    "average_listening = lambda array: np.average(array)\n",
    "point_listening = lambda array: array[20, 60]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c2922f0c9f94d1ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "listening = average_listening\n",
    "\n",
    "dampening_per_second = 1 - 1e-12\n",
    "spring_strength = 480000\n",
    "min_mass = 0.00125\n",
    "max_mass = 3.2\n",
    "\n",
    "sonification_duration = 5\n",
    "sonification_duration = np.min([duration, sonification_duration])\n",
    "\n",
    "sample_rate = 44100\n",
    "dampening_per_sample = 1 - pow(1 - dampening_per_second, 1 / sample_rate)\n",
    "\n",
    "spatial_step = 4\n",
    "m = n // spatial_step"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42705b8bf0cd838d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "num_simulated_steps = sonification_duration * sample_rate\n",
    "\n",
    "deflections = np.zeros((m, m))\n",
    "speeds = np.zeros((m, m), dtype=np.float64)\n",
    "forces = np.zeros((m, m), dtype=np.float64)\n",
    "#speeds[excitement_point] = 1\n",
    "\n",
    "masses = np.empty((m, m))\n",
    "data = frames[0, ::spatial_step, ::spatial_step]\n",
    "last_data = frames[0, ::spatial_step, ::spatial_step]\n",
    "\n",
    "\n",
    "audio = np.empty(num_simulated_steps)\n",
    "\n",
    "for sample in range(num_simulated_steps):\n",
    "    \n",
    "    simulation_index = int(sample / sample_rate * sim_fps)\n",
    "    last_data = data\n",
    "    #data = get_interpolated(frames, [sample / sample_rate * fps])\n",
    "    data = frames[simulation_index, ::spatial_step, ::spatial_step]\n",
    "    \n",
    "    masses = min_mass + (max_mass - min_mass) * np.abs(data)\n",
    "    \n",
    "    # Internal cells interaction\n",
    "    #'''\n",
    "    forces = np.zeros((m, m), dtype=np.float64)\n",
    "    # Springs \n",
    "    forces[1:  ,  :  ] += spring_strength * (deflections[:-1, :] - deflections[1:  , :]) # Bottom\n",
    "    forces[ :-1,  :  ] += spring_strength * (deflections[1:  , :] - deflections[:-1, :]) # Top\n",
    "    forces[ :  , 1:  ] += spring_strength * (deflections[:  , :-1] - deflections[:  , 1:]) # Left\n",
    "    forces[ :  ,  :-1] += spring_strength * (deflections[:  , 1:] - deflections[:  , :-1]) # Right\n",
    "    \n",
    "    # Fixed points\n",
    "    #forces[::n-1, ::n-1] = 0 # fixed corners\n",
    "    forces[::m-1, :] = 0 # fixed top & bottom\n",
    "    forces[:, ::m-1] = 0 # fixed sides\n",
    "    \n",
    "    '''\n",
    "    # Springs compact\n",
    "    forces[1:-1, 1:-1] = spring_amount * (deflections[:-2, 1:-1] + deflections[2:, 1:-1] +\n",
    "                          deflections[1:-1, :-2] + deflections[1:-1, 2:] -\n",
    "                          4 * deflections[1:-1, 1:-1])\n",
    "    '''\n",
    "\n",
    "    # Add noise\n",
    "    # TODO: As force or directly at speeds?\n",
    "    # Forces seems to be better\n",
    "    forces[1:-1, 1:-1] += np.abs(np.abs(last_data) - np.abs(data))[1:-1, 1:-1] * (2 * np.random.random((m-2, m-2)) - 1)\n",
    "\n",
    "    # Update speeds with forces, apply dampening\n",
    "    speeds += forces / masses / sample_rate\n",
    "    speeds *= 1 - dampening_per_sample #/ masses\n",
    "    \n",
    "    deflections += speeds / sample_rate\n",
    "\n",
    "    audio[sample] = listening(deflections)\n",
    "\n",
    "    #'''\n",
    "    if sample % (sample_rate * sonification_duration // 5) == 0:\n",
    "        scale = np.max(np.abs(deflections))\n",
    "        plt.pcolormesh(deflections, vmin=-scale, vmax=scale, cmap='Spectral')\n",
    "        plt.colorbar()\n",
    "        plt.title(f\"{round(sample/sample_rate, 2) }s / {sample} samples\")\n",
    "        plt.show()\n",
    "    #'''"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d6e57e6fe26bef2",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "audio[:1000]  *= np.square(np.linspace(start=0, stop=1, num=1000, endpoint=False))\n",
    "audio[-1000:] *= np.square(np.linspace(start=1, stop=0, num=1000, endpoint=False))\n",
    "audio_filename = f'output/sonification_{datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")}.wav'\n",
    "write(audio_filename, sample_rate, np.round((audio - np.average(audio)) / np.max(np.abs(audio - np.average(audio))) * 32767).astype(np.int16))\n",
    "print(f\"Sonification saved as {audio_filename}\")\n",
    "Audio(audio, rate=sample_rate)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d207c2646d2fabe9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "plt.plot(audio)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a755b692f911a496",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Combine Audio & Video"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f59e8aba895eac4f"
  },
  {
   "cell_type": "code",
   "source": [
    "combined_filename = f'output/combination_{datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")}.mp4'\n",
    "\n",
    "# Construct the ffmpeg command to combine video and audio\n",
    "ffmpeg_command = [\n",
    "    'ffmpeg',\n",
    "    '-i', video_filename,   # Input video file\n",
    "    '-i', audio_filename,   # Input audio file\n",
    "    '-c:v', 'copy',         # Copy the video stream\n",
    "    '-c:a', 'aac',          # Encode the audio to AAC (necessary for some formats)\n",
    "    '-shortest',            # Finish encoding when the shortest input stream ends\n",
    "    combined_filename         # Output file\n",
    "]\n",
    "\n",
    "# Execute the command\n",
    "subprocess.run(ffmpeg_command)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "888c2aa38e2109bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    " "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35a10dfc55356a00",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
