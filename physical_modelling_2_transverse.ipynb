{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Physical Modelling 2\n",
    "- Transverse Wave\n",
    "- Can reduce spatial resolution\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.patches as patches\n",
    "from IPython.display import Audio\n",
    "from scipy.io.wavfile import write\n",
    "from datetime import datetime\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_interpolated(array, index):\n",
    "    if not hasattr(index, \"__len__\") or len(index) < 1: return array # if scalar\n",
    "    return (1 - (index[0] % 1)) * get_interpolated(array[int(np.floor(index[0]))], index[1:]) + (index[0] % 1) * get_interpolated(array[int(np.ceil(index[0]))], index[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_interpolated(np.array([[1, 2],[3, 4]]), [0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import simulation\n",
    "\n",
    "n = 128\n",
    "sim_speed = 0.004\n",
    "sim_fps = 400\n",
    "duration = 6\n",
    "frame_amount = duration * sim_fps\n",
    "\n",
    "initial_state = np.array([[simulation.gaussian(x, y, n, offset=[-0.6, 0.0], width=0.15, height=0.15) for x in range(n)] for y in range(n)])\n",
    "potential = np.array([[simulation.parabola(x, y, n, offset=(0, 0), factor=(10000, 10000)) for x in range(n)] for y in range(n)])\n",
    "\n",
    "barrier_x = n//2 - 1\n",
    "barrier_width = 2\n",
    "multi_slit = [(-15, -13), (-8, -6), (-1, 1), (6, 8), (13, 15)]\n",
    "double_slit = [(-4, -2), (2, 4)]\n",
    "single_slit = [(-2, 2)]\n",
    "slits = double_slit\n",
    "\n",
    "frames = simulation.sim(n, sim_fps, duration, slits, barrier_x, barrier_width, sim_speed, initial_state=initial_state, potential=potential, normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import video\n",
    "\n",
    "# save video\n",
    "video_filename, anim = video.create(frames, 20, 1, frame_amount, sim_fps, slits, barrier_x, barrier_width, n)\n",
    "\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "# Sonification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_listening = lambda array: np.average(array)\n",
    "point_listening = lambda array: array[20, 60]\n",
    "\n",
    "scaling_none = lambda deflections, data: deflections\n",
    "scaling_data = lambda deflections, data: deflections * np.abs(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 4 * 44100 # 176000\n",
    "\n",
    "listening = average_listening\n",
    "scaling = scaling_data\n",
    "excitement_point = np.array([64, 28])\n",
    "\n",
    "dampening_per_second = 0.9 # 1 - 1e-3\n",
    "spring_strength = sample_rate * 600\n",
    "min_mass = 1 # 0.01 #0.00125\n",
    "max_mass = 0.01 # 1 #3.2\n",
    "\n",
    "spatial_step = 4\n",
    "\n",
    "sonification_duration = duration\n",
    "\n",
    "sonification_duration = np.min([duration, sonification_duration]).astype(int)\n",
    "dampening_per_sample = 1 - pow(1 - dampening_per_second, 1 / sample_rate)\n",
    "m = n // spatial_step\n",
    "excitement_point = excitement_point // spatial_step\n",
    "num_simulated_steps = sonification_duration * sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "deflections = np.zeros((m, m))\n",
    "speeds = np.zeros((m, m), dtype=np.float64)\n",
    "forces = np.zeros((m, m), dtype=np.float64)\n",
    "\n",
    "# speeds[tuple(excitement_point)] = 1\n",
    "\n",
    "masses = np.empty((m, m))\n",
    "data = frames[0, ::spatial_step, ::spatial_step]\n",
    "last_data = frames[0, ::spatial_step, ::spatial_step]\n",
    "\n",
    "\n",
    "audio = np.empty(num_simulated_steps)\n",
    "\n",
    "for sample in range(num_simulated_steps):\n",
    "    \n",
    "    simulation_index = int(sample / sample_rate * sim_fps)\n",
    "    last_data = data\n",
    "    #data = get_interpolated(frames, [sample / sample_rate * fps])\n",
    "    data = frames[simulation_index, ::spatial_step, ::spatial_step]\n",
    "    #data = frames[0, ::spatial_step, ::spatial_step] # just first frame\n",
    "    #data = frames[int(2.4 * sim_fps), ::spatial_step, ::spatial_step] # second 2.4 after first gothrough\n",
    "    #data = 1 * np.ones((m, m)) # static plate\n",
    "    \n",
    "    masses = min_mass + (max_mass - min_mass) * np.abs(data)\n",
    "    \n",
    "    # Internal cells interaction\n",
    "    #'''\n",
    "    forces = np.zeros((m, m), dtype=np.float64)\n",
    "    # Springs \n",
    "    forces[1:  ,  :  ] += spring_strength * (deflections[:-1, :] - deflections[1:  , :]) # Bottom\n",
    "    forces[ :-1,  :  ] += spring_strength * (deflections[1:  , :] - deflections[:-1, :]) # Top\n",
    "    forces[ :  , 1:  ] += spring_strength * (deflections[:  , :-1] - deflections[:  , 1:]) # Left\n",
    "    forces[ :  ,  :-1] += spring_strength * (deflections[:  , 1:] - deflections[:  , :-1]) # Right\n",
    "    \n",
    "    # Fixed points\n",
    "    #forces[::n-1, ::n-1] = 0 # fixed corners\n",
    "    forces[::m-1, :] = 0 # fixed top & bottom\n",
    "    forces[:, ::m-1] = 0 # fixed sides\n",
    "    \n",
    "    '''\n",
    "    # Springs compact\n",
    "    forces[1:-1, 1:-1] = spring_amount * (deflections[:-2, 1:-1] + deflections[2:, 1:-1] +\n",
    "                          deflections[1:-1, :-2] + deflections[1:-1, 2:] -\n",
    "                          4 * deflections[1:-1, 1:-1])\n",
    "    '''\n",
    "\n",
    "    # Add noise\n",
    "    # TODO: As force or directly at speeds?\n",
    "    # Forces seems to be better\n",
    "    difference = np.abs(data) - np.abs(last_data)\n",
    "    # forces[1:-1, 1:-1] += np.where(difference > 0, difference, 0)[1:-1, 1:-1] * (2 * np.random.random((m-2, m-2)) - 1)\n",
    "    forces[1:-1, 1:-1] += np.abs(difference)[1:-1, 1:-1] * (2 * np.random.random((m-2, m-2)) - 1)\n",
    "\n",
    "    # Update speeds with forces, apply dampening\n",
    "    speeds += forces / masses / sample_rate\n",
    "    speeds *= 1 - dampening_per_sample #/ masses\n",
    "    \n",
    "    deflections += speeds / sample_rate\n",
    "\n",
    "    audio[sample] = listening(scaling(deflections, data))\n",
    "\n",
    "    #'''\n",
    "    if sample % (sample_rate * sonification_duration // 5) == 0:\n",
    "        scale = np.max(np.abs(scaling(deflections, data)))\n",
    "        plt.pcolormesh(scaling(deflections, data), vmin=-scale, vmax=scale, cmap='Spectral')\n",
    "        plt.colorbar()\n",
    "        plt.title(f\"{round(sample/sample_rate, 2) }s / {sample} samples\")\n",
    "        plt.show()\n",
    "    #'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "fade = 0.005\n",
    "if fade > 0:\n",
    "    fade_samples = int(sample_rate * fade)\n",
    "    audio[:fade_samples]  *= np.square(np.linspace(start=0, stop=1, num=fade_samples, endpoint=False))\n",
    "    audio[-fade_samples:] *= np.square(np.linspace(start=1, stop=0, num=fade_samples, endpoint=False))\n",
    "audio_filename = f'output/sonification_{datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")}.wav'\n",
    "write(audio_filename, sample_rate, np.round((audio - np.average(audio)) / np.max(np.abs(audio - np.average(audio))) * 32767).astype(np.int16))\n",
    "print(f\"Sonification saved as {audio_filename}\")\n",
    "Audio(audio, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "# Combine Audio & Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_filename = f'output/combination_{datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")}.mp4'\n",
    "\n",
    "# Construct the ffmpeg command to combine video and audio\n",
    "ffmpeg_command = [\n",
    "    'ffmpeg',\n",
    "    '-i', video_filename,   # Input video file\n",
    "    '-i', audio_filename,   # Input audio file\n",
    "    '-c:v', 'copy',         # Copy the video stream\n",
    "    '-c:a', 'aac',          # Encode the audio to AAC (necessary for some formats)\n",
    "    '-shortest',            # Finish encoding when the shortest input stream ends\n",
    "    combined_filename         # Output file\n",
    "]\n",
    "\n",
    "# Execute the command\n",
    "subprocess.run(ffmpeg_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
