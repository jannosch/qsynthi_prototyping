{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Physical Modelling 4\n",
    "- Preliminary/Testing Version!\n",
    "- CUDA acceleration testing (got up to 10x improvement)\n",
    "- "
   ],
   "id": "6789b86632c6f52d"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import cupy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.patches as patches\n",
    "from IPython.display import Audio\n",
    "from scipy.io.wavfile import write\n",
    "from datetime import datetime\n",
    "import subprocess\n",
    "import timeit"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def get_interpolated(array, index):\n",
    "    if not hasattr(index, \"__len__\") or len(index) < 1: return array # if scalar\n",
    "    return (1 - (index[0] % 1)) * get_interpolated(array[int(np.floor(index[0]))], index[1:]) + (index[0] % 1) * get_interpolated(array[int(np.ceil(index[0]))], index[1:])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43a188074d7eaff3",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def interpolate_1d(array, indices):\n",
    "    t = indices.reshape(-1, 1, 1) % 1\n",
    "    left = array[np.floor(indices).astype(np.int64)]\n",
    "    right = array[np.ceil(indices).astype(np.int64)]\n",
    "    print(\"first step done\")\n",
    "    return (1 - t) * left + t * right"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f08c3f0677fad011",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "interpolate_1d(np.array([[1, 2],[3, 4]]), np.array([0.5]))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "954deb97c398862c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Simulation",
   "id": "8829280fd1e1e5f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 29,
   "source": [
    "import simulation\n",
    "\n",
    "n = 128\n",
    "sim_speed = 0.004\n",
    "sim_fps = 400\n",
    "duration = 5\n",
    "frame_amount = duration * sim_fps\n",
    "\n",
    "double_slit = [(-4, -2), (2, 4)]\n",
    "single_slit = [(-2, 2)]\n",
    "slits = double_slit\n",
    "\n",
    "frames = simulation.sim(n, sim_fps, duration, slits, sim_speed)"
   ],
   "id": "fc66d139f7440400"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Video"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6cae44c239c53b0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 39,
   "source": [
    "# create visual barrier for plot\n",
    "def visual_barrier(barrier_gaps):\n",
    "    start = 0\n",
    "    rects = []\n",
    "    for g in barrier_gaps:\n",
    "        end = n//2 + g[0]\n",
    "        rect = patches.Rectangle((n//2 - 1.5, start - 0.5), 1, end - start, linewidth=0, facecolor='#60b0ff')\n",
    "        start = n//2 + g[1]\n",
    "        rects.append(rect)\n",
    "    rects.append(patches.Rectangle((n//2 - 1.5, start - 0.5), 1, n - start, linewidth=0, facecolor='#60b0ff'))\n",
    "    return rects"
   ],
   "id": "7db20ff70a000bf8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# FuncAnimation\n",
    "video_fps = 20\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.axis('off')  # big performance boost\n",
    "\n",
    "data = pow(np.abs(frames[0]), 2.0/3.0)\n",
    "cax = ax.imshow(data, cmap='inferno', vmin=0, vmax=1)\n",
    "for b in visual_barrier(slits):\n",
    "    ax.add_patch(b)\n",
    "fig.colorbar(cax)  # no performance impact (?)\n",
    "\n",
    "def animate(i):\n",
    "    cax.set_array(pow(np.abs(frames[i * sim_fps // video_fps]), 2.0/3.0))\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, frames=frame_amount * video_fps // sim_fps)\n",
    "video_filename = f'output/simulation_{datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")}.mp4'\n",
    "\n",
    "anim.save(video_filename, fps=video_fps, dpi=150, bitrate=4000)\n",
    "\n",
    "print(f'video saved as {video_filename}')"
   ],
   "id": "8bd2ccb4c47c9c10",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sonification"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "80163b117f61d1c4"
  },
  {
   "cell_type": "code",
   "source": [
    "average_parallel_listening = lambda array: np.average(array[:, :, 0])\n",
    "average_orthogonal_listening = lambda array: np.average(array[:, :, 1])\n",
    "average_norm_listening = lambda array: np.average(np.linalg.norm(array, axis=2))\n",
    "\n",
    "point_parallel_listening = lambda array: array[20, 60, 0]\n",
    "point_orthogonal_listening = lambda array: array[20, 60, 1]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c2922f0c9f94d1ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "sample_rate = 44100\n",
    "sonification_duration = 2\n",
    "sonification_duration = np.min(np.array([duration, sonification_duration]))\n",
    "\n",
    "listening = average_orthogonal_listening\n",
    "\n",
    "dampening_per_second = 1 - 1e-12\n",
    "spring_amount = sample_rate * 10\n",
    "min_mass = 0.00125\n",
    "max_mass = 3.2\n",
    "\n",
    "\n",
    "dampening_per_sample = 1 - pow(1 - dampening_per_second, 1 / sample_rate)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42705b8bf0cd838d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "num_simulated_steps = int(sonification_duration * sample_rate)\n",
    "\n",
    "springs = np.indices((n, n)).transpose((1, 2, 0))[:, :, np.newaxis, :] + np.array([[[[-1, 0], [1, 0], [0, -1], [0, 1]]]]) # indices for each connected mass point for each mass point shape: (x, y, num_springs, indices_of_other_point\n",
    "original_positions = np.indices((n, n), dtype=np.float64).transpose((1, 2, 0))\n",
    "\n",
    "masses = min_mass + (max_mass - min_mass) * np.abs(np.array(frames))\n",
    "angles = np.angle(np.array(frames))\n",
    "springs_length = 1 - np.cos(angles[:, springs[1:-1, 1:-1, :, 0], springs[1:-1, 1:-1, :, 1], np.newaxis] - angles[:, 1:-1, 1:-1, np.newaxis, np.newaxis])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34440232372cd110",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "positions = np.copy(original_positions)\n",
    "speeds = np.zeros((n, n, 2), dtype=np.float64)\n",
    "forces = np.zeros((n, n, 2), dtype=np.float64)\n",
    "\n",
    "audio = np.empty(num_simulated_steps)\n",
    "\n",
    "data = frames[0]\n",
    "\n",
    "time = [0]*10\n",
    "reps = 2000\n",
    "at_sample = []#[1000, 2000]\n",
    "\n",
    "pos_extractions = []\n",
    "\n",
    "for sample in range(num_simulated_steps):\n",
    "    #print(sample, end=\"\\r\")\n",
    "    \n",
    "    simulation_index = int(sample / sample_rate * sim_fps)\n",
    "    last_data = data\n",
    "    data = np.array(frames[simulation_index]) # no interpolation    \n",
    "\n",
    "    if sample in at_sample:\n",
    "        print('timing 0')\n",
    "        time[0] += timeit.timeit('positions[springs[1:-1, 1:-1, :, 0], springs[1:-1, 1:-1, :, 1]] - positions[1:-1, 1:-1, np.newaxis, :]', number=reps, globals=locals())\n",
    "    offsets = positions[springs[1:-1, 1:-1, :, 0], springs[1:-1, 1:-1, :, 1]] - positions[1:-1, 1:-1, np.newaxis, :]\n",
    "    \n",
    "    if sample in at_sample:\n",
    "        print('timing 1')\n",
    "        time[1] += timeit.timeit('np.linalg.norm(offsets, axis=3)[:, :, :, np.newaxis]', number=reps, globals=locals())\n",
    "    distances = np.linalg.norm(offsets, axis=3)[:, :, :, np.newaxis]\n",
    "\n",
    "    if sample in at_sample:\n",
    "        print('timing 2')\n",
    "        time[2] += timeit.timeit('np.sum(spring_amount * offsets * (distances - springs_length[simulation_index]) / distances, axis=2)', number=reps, globals=locals())\n",
    "    forces[1:-1, 1:-1] = np.sum(spring_amount * offsets * (distances - springs_length[simulation_index]) / distances, axis=2) # apply springs force\n",
    "    \n",
    "    # Add noise\n",
    "    if sample in at_sample:\n",
    "        print('timing 3')\n",
    "        time[3] += timeit.timeit('np.abs(np.abs(last_data) - np.abs(data))[1:-1, 1:-1] * (2 * np.random.random((n-2, n-2)) - 1)', number=reps, globals=locals())\n",
    "    forces[1:-1, 1:-1, 0] += np.abs(np.abs(last_data) - np.abs(data))[1:-1, 1:-1] * (2 * np.random.random((n-2, n-2)) - 1)\n",
    "\n",
    "    # Update speeds with forces, apply dampening\n",
    "    if sample in at_sample:\n",
    "        print('timing 4')\n",
    "        time[4] += timeit.timeit('forces / masses[simulation_index, :, :, np.newaxis] / sample_rate', number=reps, globals=locals())\n",
    "    speeds += forces / masses[simulation_index, :, :, np.newaxis] / sample_rate\n",
    "    speeds *= 1 - dampening_per_sample #/ masses[simulation_index, :, :, np.newaxis]\n",
    "\n",
    "    if sample in at_sample:\n",
    "        print('timing 5')\n",
    "        time[5] += timeit.timeit('speeds / sample_rate', number=reps, globals=locals())\n",
    "    positions += speeds / sample_rate\n",
    "\n",
    "    if sample in at_sample:\n",
    "        print('timing 6')\n",
    "        time[6] += timeit.timeit('listening(positions - original_positions)', number=reps, globals=locals())\n",
    "    audio[sample] = listening(positions - original_positions)\n",
    "    \n",
    "    if len(at_sample) > 0 and sample == at_sample[-1]:\n",
    "        break\n",
    "\n",
    "    if sample % (sample_rate * sonification_duration // 5) == 0:\n",
    "        pos_extractions.append((sample, np.copy(positions)))\n",
    "        print(f\"samples: {sample}\", end=\"\\r\")\n",
    "        # plot_data = np.abs(np.linalg.norm(positions - original_positions, axis=2))\n",
    "        # scale = np.max(plot_data)\n",
    "        # plt.pcolormesh(plot_data.get(), vmin=-scale, vmax=scale, cmap='Spectral')\n",
    "        # plt.colorbar()\n",
    "        # plt.title(f\"{round(sample/sample_rate, 2) }s / {sample} samples\")\n",
    "        # plt.show()\n",
    "\n",
    "# timeit results\n",
    "for i, t in enumerate(np.array(time)):\n",
    "    if t == 0 or len(at_sample) == 0:\n",
    "        continue\n",
    "    print(f'{i}   {t*1000:8.2f}   {t*1000/(reps*len(at_sample)):4.4f}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d6e57e6fe26bef2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for p in pos_extractions:\n",
    "    plot_data = np.abs(np.linalg.norm(p[1] - original_positions, axis=2))\n",
    "    scale = np.max(plot_data)\n",
    "    plt.pcolormesh(plot_data.get(), vmin=-scale, vmax=scale, cmap='Spectral')\n",
    "    plt.colorbar()\n",
    "    plt.title(f\"{round(p[0]/sample_rate, 2) }s / {p[0]} samples\")\n",
    "    plt.show()"
   ],
   "id": "11c67165dcbc4667",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "audio[:1000]  *= np.square(np.linspace(start=0, stop=1, num=1000, endpoint=False))\n",
    "audio[-1000:] *= np.square(np.linspace(start=1, stop=0, num=1000, endpoint=False))\n",
    "audio_filename = f'sonification_{datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")}.wav'\n",
    "write(audio_filename, sample_rate, np.round((audio - np.average(audio)) / np.max(np.abs(audio - np.average(audio))) * 32767).astype(np.int16).get())\n",
    "print(f\"Sonification saved as {audio_filename}\")\n",
    "Audio(audio.get(), rate=sample_rate)"
   ],
   "id": "d207c2646d2fabe9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "plt.plot(audio.get())",
   "metadata": {
    "collapsed": false
   },
   "id": "a755b692f911a496",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Combine Audio & Video"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f59e8aba895eac4f"
  },
  {
   "cell_type": "code",
   "source": [
    "combined_filename = f'combination_{datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")}.mp4'\n",
    "\n",
    "# Construct the ffmpeg command to combine video and audio\n",
    "ffmpeg_command = [\n",
    "    'ffmpeg',\n",
    "    '-i', video_filename,   # Input video file\n",
    "    '-i', audio_filename,   # Input audio file\n",
    "    '-c:v', 'copy',         # Copy the video stream\n",
    "    '-c:a', 'aac',          # Encode the audio to AAC (necessary for some formats)\n",
    "    '-shortest',            # Finish encoding when the shortest input stream ends\n",
    "    combined_filename         # Output file\n",
    "]\n",
    "\n",
    "# Execute the command\n",
    "subprocess.run(ffmpeg_command)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "888c2aa38e2109bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    " "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35a10dfc55356a00",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
