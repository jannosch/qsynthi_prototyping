{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Physical Modelling 4\n",
    "- Preliminary/Testing Version!\n",
    "- CUDA acceleration testing (got up to 10x improvement)\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as np\n",
    "import numpy as np_\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.patches as patches\n",
    "from IPython.display import Audio\n",
    "from scipy.io.wavfile import write\n",
    "from datetime import datetime\n",
    "import subprocess\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_interpolated(array, index):\n",
    "    if not hasattr(index, \"__len__\") or len(index) < 1: return array # if scalar\n",
    "    return (1 - (index[0] % 1)) * get_interpolated(array[int(np.floor(index[0]))], index[1:]) + (index[0] % 1) * get_interpolated(array[int(np.ceil(index[0]))], index[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_1d(array, indices):\n",
    "    t = indices.reshape(-1, 1, 1) % 1\n",
    "    left = array[np.floor(indices).astype(np.int64)]\n",
    "    right = array[np.ceil(indices).astype(np.int64)]\n",
    "    print(\"first step done\")\n",
    "    return (1 - t) * left + t * right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolate_1d(np.array([[1, 2],[3, 4]]), np.array([0.5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import simulation\n",
    "\n",
    "n = 128\n",
    "sim_speed = 0.004\n",
    "sim_fps = 400\n",
    "duration = 6\n",
    "frame_amount = duration * sim_fps\n",
    "\n",
    "initial_state = np.array([[simulation.gaussian(x, y, n, offset=[-0.6, 0.0], width=0.15, height=0.15) for x in range(n)] for y in range(n)])\n",
    "potential = np.array([[simulation.parabola(x, y, n, offset=(0, 0), factor=(10000, 10000)) for x in range(n)] for y in range(n)])\n",
    "\n",
    "barrier_x = n//2 - 1\n",
    "barrier_width = 2\n",
    "multi_slit = [(-15, -13), (-8, -6), (-1, 1), (6, 8), (13, 15)]\n",
    "double_slit = [(-4, -2), (2, 4)]\n",
    "single_slit = [(-2, 2)]\n",
    "slits = double_slit\n",
    "\n",
    "frames = simulation.sim(n, sim_fps, duration, slits, barrier_x, barrier_width, sim_speed, initial_state=initial_state, potential=potential)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import video\n",
    "\n",
    "# save video\n",
    "video_filename, anim = video.create(frames, 20, 1, frame_amount, sim_fps, slits, barrier_x, barrier_width, n)\n",
    "\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "# Sonification phys 3\n",
    "- CUDA acceleration is actually slower on this code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_parallel_listening = lambda array: np.average(array[:, :, 0])\n",
    "average_orthogonal_listening = lambda array: np.average(array[:, :, 1])\n",
    "average_norm_listening = lambda array: np.average(np.linalg.norm(array, axis=2))\n",
    "\n",
    "point_parallel_listening = lambda array: array[20, 60, 0]\n",
    "point_orthogonal_listening = lambda array: array[20, 60, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 44100\n",
    "sonification_duration = 2\n",
    "sonification_duration = int(np.min(np.array([duration, sonification_duration])))\n",
    "\n",
    "listening = average_orthogonal_listening\n",
    "\n",
    "dampening_per_second = 1 - 1e-15\n",
    "spring_amount = sample_rate * 15\n",
    "min_mass = 0.00125\n",
    "max_mass = 3.2\n",
    "\n",
    "spatial_step = 4\n",
    "m = n // spatial_step\n",
    "\n",
    "dampening_per_sample = 1 - pow(1 - dampening_per_second, 1 / sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_simulated_steps = sonification_duration * sample_rate\n",
    "original_positions = np.indices((m, m), dtype=np.float64).transpose((1, 2, 0))\n",
    "positions = np.copy(original_positions)\n",
    "speeds = np.zeros((m-2, m-2, 2), dtype=np.float64)\n",
    "forces = np.zeros((m-2, m-2, 2), dtype=np.float64)\n",
    "\n",
    "audio = np.empty(num_simulated_steps)\n",
    "\n",
    "data = frames[0, ::spatial_step, ::spatial_step]\n",
    "\n",
    "for sample in range(num_simulated_steps):\n",
    "    \n",
    "    simulation_index = int(sample / sample_rate * sim_fps)\n",
    "    last_data = data\n",
    "    data = frames[simulation_index, ::spatial_step, ::spatial_step] # no interpolation\n",
    "    \n",
    "    masses = (min_mass + (max_mass - min_mass) * np.abs(data))[1:-1, 1:-1, np.newaxis]\n",
    "    angles = np.angle(data)\n",
    "    \n",
    "    bottom_offset = positions[ :-2, 1:-1] - positions[1:-1, 1:-1]\n",
    "    top_offset    = positions[2:  , 1:-1] - positions[1:-1, 1:-1]\n",
    "    left_offset   = positions[1:-1,  :-2] - positions[1:-1, 1:-1]\n",
    "    right_offset  = positions[1:-1, 2:  ] - positions[1:-1, 1:-1]\n",
    "    \n",
    "    bottom_spring_length = (1 - np.cos(angles[ :-2, 1:-1] - angles[1:-1, 1:-1]))\n",
    "    top_spring_length    = (1 - np.cos(angles[2:  , 1:-1] - angles[1:-1, 1:-1]))\n",
    "    left_spring_length   = (1 - np.cos(angles[1:-1,  :-2] - angles[1:-1, 1:-1]))\n",
    "    right_spring_length  = (1 - np.cos(angles[1:-1, 2:  ] - angles[1:-1, 1:-1]))\n",
    "\n",
    "    forces = np.zeros((m-2, m-2, 2), dtype=np.float64)\n",
    "    forces += spring_amount * bottom_offset * (1 - bottom_spring_length / np.linalg.norm(bottom_offset, axis=2))[:, :, np.newaxis]\n",
    "    forces += spring_amount * top_offset    * (1 - top_spring_length    / np.linalg.norm(top_offset   , axis=2))[:, :, np.newaxis]\n",
    "    forces += spring_amount * left_offset   * (1 - left_spring_length   / np.linalg.norm(left_offset  , axis=2))[:, :, np.newaxis]\n",
    "    forces += spring_amount * right_offset  * (1 - right_spring_length  / np.linalg.norm(right_offset , axis=2))[:, :, np.newaxis]\n",
    "    \n",
    "    # Add noise\n",
    "    forces[:, :, 0] += np.abs(np.abs(last_data) - np.abs(data))[1:-1, 1:-1] * (2 * np.random.random((m-2, m-2)) - 1)\n",
    "\n",
    "    # Update speeds with forces, apply dampening\n",
    "    speeds += forces / masses / sample_rate\n",
    "    speeds *= 1 - dampening_per_sample #/ masses[:, :, np.newaxis]\n",
    "    \n",
    "    positions[1:-1, 1:-1] += speeds / sample_rate\n",
    "\n",
    "    audio[sample] = listening(positions - original_positions)\n",
    "\n",
    "    if sample % (sample_rate * sonification_duration // 5) == 0:\n",
    "        print(f\"samples: {sample}\", end=\"\\r\")\n",
    "    '''\n",
    "    #if sample % (sample_rate // 100) == 0: print(f\"{round(sample/sample_rate, 3)}s\")\n",
    "    if sample % (sample_rate * sonification_duration // 5) == 0:\n",
    "        plot_data = np.abs(np.linalg.norm(positions - original_positions, axis=2))\n",
    "        scale = np.max(plot_data)\n",
    "        plt.pcolormesh(plot_data, vmin=-scale, vmax=scale, cmap='Spectral')\n",
    "        plt.colorbar()\n",
    "        plt.title(f\"{round(sample/sample_rate, 2)}s / {sample} samples\")\n",
    "        plt.show()\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "# Sonification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_parallel_listening = lambda array: np.average(array[:, :, 0])\n",
    "average_orthogonal_listening = lambda array: np.average(array[:, :, 1])\n",
    "average_norm_listening = lambda array: np.average(np.linalg.norm(array, axis=2))\n",
    "\n",
    "point_parallel_listening = lambda array: array[20, 60, 0]\n",
    "point_orthogonal_listening = lambda array: array[20, 60, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 44100\n",
    "sonification_duration = 2\n",
    "sonification_duration = int(np.min(np.array([duration, sonification_duration])))\n",
    "\n",
    "listening = average_orthogonal_listening\n",
    "\n",
    "dampening_per_second = 1 - 1e-12\n",
    "spring_amount = sample_rate * 10\n",
    "min_mass = 0.00125\n",
    "max_mass = 3.2\n",
    "\n",
    "\n",
    "dampening_per_sample = 1 - pow(1 - dampening_per_second, 1 / sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_simulated_steps = sonification_duration * sample_rate\n",
    "\n",
    "springs = np.indices((n, n)).transpose((1, 2, 0))[:, :, np.newaxis, :] + np.array([[[[-1, 0], [1, 0], [0, -1], [0, 1]]]]) # indices for each connected mass point for each mass point shape: (x, y, num_springs, indices_of_other_point\n",
    "original_positions = np.indices((n, n), dtype=np.float64).transpose((1, 2, 0))\n",
    "\n",
    "masses = min_mass + (max_mass - min_mass) * np.abs(np.array(frames))\n",
    "angles = np.angle(np.array(frames))\n",
    "springs_length = 1 - np.cos(angles[:, springs[1:-1, 1:-1, :, 0], springs[1:-1, 1:-1, :, 1], np.newaxis] - angles[:, 1:-1, 1:-1, np.newaxis, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = np.copy(original_positions)\n",
    "speeds = np.zeros((n, n, 2), dtype=np.float64)\n",
    "forces = np.zeros((n, n, 2), dtype=np.float64)\n",
    "\n",
    "audio = np.empty(num_simulated_steps)\n",
    "\n",
    "data = frames[0]\n",
    "\n",
    "time = [0]*10\n",
    "reps = 2000\n",
    "at_sample = []#[1000, 2000]\n",
    "\n",
    "pos_extractions = []\n",
    "\n",
    "for sample in range(num_simulated_steps):\n",
    "    #print(sample, end=\"\\r\")\n",
    "    \n",
    "    simulation_index = int(sample / sample_rate * sim_fps)\n",
    "    last_data = data\n",
    "    data = np.array(frames[simulation_index]) # no interpolation    \n",
    "\n",
    "    if sample in at_sample:\n",
    "        print('timing 0')\n",
    "        time[0] += timeit.timeit('positions[springs[1:-1, 1:-1, :, 0], springs[1:-1, 1:-1, :, 1]] - positions[1:-1, 1:-1, np.newaxis, :]', number=reps, globals=locals())\n",
    "    offsets = positions[springs[1:-1, 1:-1, :, 0], springs[1:-1, 1:-1, :, 1]] - positions[1:-1, 1:-1, np.newaxis, :]\n",
    "    \n",
    "    if sample in at_sample:\n",
    "        print('timing 1')\n",
    "        time[1] += timeit.timeit('np.linalg.norm(offsets, axis=3)[:, :, :, np.newaxis]', number=reps, globals=locals())\n",
    "    distances = np.linalg.norm(offsets, axis=3)[:, :, :, np.newaxis]\n",
    "\n",
    "    if sample in at_sample:\n",
    "        print('timing 2')\n",
    "        time[2] += timeit.timeit('np.sum(spring_amount * offsets * (distances - springs_length[simulation_index]) / distances, axis=2)', number=reps, globals=locals())\n",
    "    forces[1:-1, 1:-1] = np.sum(spring_amount * offsets * (distances - springs_length[simulation_index]) / distances, axis=2) # apply springs force\n",
    "    \n",
    "    # Add noise\n",
    "    if sample in at_sample:\n",
    "        print('timing 3')\n",
    "        time[3] += timeit.timeit('np.abs(np.abs(last_data) - np.abs(data))[1:-1, 1:-1] * (2 * np.random.random((n-2, n-2)) - 1)', number=reps, globals=locals())\n",
    "    forces[1:-1, 1:-1, 0] += np.abs(np.abs(last_data) - np.abs(data))[1:-1, 1:-1] * (2 * np.random.random((n-2, n-2)) - 1)\n",
    "\n",
    "    # Update speeds with forces, apply dampening\n",
    "    if sample in at_sample:\n",
    "        print('timing 4')\n",
    "        time[4] += timeit.timeit('forces / masses[simulation_index, :, :, np.newaxis] / sample_rate', number=reps, globals=locals())\n",
    "    speeds += forces / masses[simulation_index, :, :, np.newaxis] / sample_rate\n",
    "    speeds *= 1 - dampening_per_sample #/ masses[simulation_index, :, :, np.newaxis]\n",
    "\n",
    "    if sample in at_sample:\n",
    "        print('timing 5')\n",
    "        time[5] += timeit.timeit('speeds / sample_rate', number=reps, globals=locals())\n",
    "    positions += speeds / sample_rate\n",
    "\n",
    "    if sample in at_sample:\n",
    "        print('timing 6')\n",
    "        time[6] += timeit.timeit('listening(positions - original_positions)', number=reps, globals=locals())\n",
    "    audio[sample] = listening(positions - original_positions)\n",
    "    \n",
    "    if len(at_sample) > 0 and sample == at_sample[-1]:\n",
    "        break\n",
    "\n",
    "    if sample % (sample_rate * sonification_duration // 5) == 0:\n",
    "        pos_extractions.append((sample, np.copy(positions)))\n",
    "        print(f\"samples: {sample}\", end=\"\\r\")\n",
    "        # plot_data = np.abs(np.linalg.norm(positions - original_positions, axis=2))\n",
    "        # scale = np.max(plot_data)\n",
    "        # plt.pcolormesh(plot_data.get(), vmin=-scale, vmax=scale, cmap='Spectral')\n",
    "        # plt.colorbar()\n",
    "        # plt.title(f\"{round(sample/sample_rate, 2) }s / {sample} samples\")\n",
    "        # plt.show()\n",
    "\n",
    "# timeit results\n",
    "for i, t in enumerate(np.array(time)):\n",
    "    if t == 0 or len(at_sample) == 0:\n",
    "        continue\n",
    "    print(f'{i}   {t*1000:8.2f}   {t*1000/(reps*len(at_sample)):4.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in pos_extractions:\n",
    "    plot_data = np.abs(np.linalg.norm(p[1] - original_positions, axis=2))\n",
    "    scale = np.max(plot_data)\n",
    "    plt.pcolormesh(plot_data.get(), vmin=-scale, vmax=scale, cmap='Spectral')\n",
    "    plt.colorbar()\n",
    "    plt.title(f\"{round(p[0]/sample_rate, 2) }s / {p[0]} samples\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio[:1000]  *= np.square(np.linspace(start=0, stop=1, num=1000, endpoint=False))\n",
    "audio[-1000:] *= np.square(np.linspace(start=1, stop=0, num=1000, endpoint=False))\n",
    "audio_filename = f'output/sonification_{datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")}.wav'\n",
    "write(audio_filename, sample_rate, np.round((audio - np.average(audio)) / np.max(np.abs(audio - np.average(audio))) * 32767).astype(np.int16).get())\n",
    "print(f\"Sonification saved as {audio_filename}\")\n",
    "Audio(audio.get(), rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(audio.get())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "# Combine Audio & Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_filename = f'combination_{datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")}.mp4'\n",
    "\n",
    "# Construct the ffmpeg command to combine video and audio\n",
    "ffmpeg_command = [\n",
    "    'ffmpeg',\n",
    "    '-i', video_filename,   # Input video file\n",
    "    '-i', audio_filename,   # Input audio file\n",
    "    '-c:v', 'copy',         # Copy the video stream\n",
    "    '-c:a', 'aac',          # Encode the audio to AAC (necessary for some formats)\n",
    "    '-shortest',            # Finish encoding when the shortest input stream ends\n",
    "    combined_filename         # Output file\n",
    "]\n",
    "\n",
    "# Execute the command\n",
    "subprocess.run(ffmpeg_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
